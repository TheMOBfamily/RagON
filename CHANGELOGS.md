# CHANGELOGS - Mini-RAG

**PhiÃªn báº£n**: 0.3
**TÃ¡c giáº£**: LÃ¢m Thanh Phong - TrÆ°á»ng Äáº¡i Há»c NgÃ¢n HÃ ng Tp. Há»“ ChÃ­ Minh
**NgÃ y cáº­p nháº­t**: 20/11/2025

## PhiÃªn báº£n 0.3 (20/11/2025)

### ğŸš€ Performance Optimization - Shared Memory Cache

#### /dev/shm/ Cache Implementation
- **Apply to multi-query system**: TÃ­ch há»£p SharedMemoryCache vÃ o `standalone_loader.py`
- **Reuse existing modules**: DRY principle - dÃ¹ng `shm_cache.py` tá»« minirag package
- **Smart invalidation**: Manifest hash tracking Ä‘á»ƒ auto-invalidate khi PDFs thay Ä‘á»•i
- **Zero architecture change**: Transparent caching, khÃ´ng cáº§n sá»­a `run-multiquery.sh`

#### Performance Gains
- **Cold start**: 7.29s (load from disk + cache to /dev/shm/)
- **Warm hit**: 2.88s (load from /dev/shm/) â†’ **2.5x faster**
- **Cache size**: ~90MB per source, persistent across process restarts
- **Memory footprint**: Fixed cache trong RAM, khÃ´ng tÄƒng theo sá»‘ queries

#### Code Quality
- **Clean Code maintained**: 149 LOC < 150 LOC limit (CLAUDE.md standard)
- **SSOT principle**: Config managed centrally trong `config.py`
- **SRP compliance**: Cache separated into 3 modules (cache, validator, cleanup)
- **Backward compatible**: Existing code works unchanged

#### Technical Details
- **Cache location**: `/dev/shm/minirag_faiss_<hash>.pkl`
- **Cache key**: MD5(path + manifest_hash)[:16]
- **Metadata tracking**: `.meta` file vá»›i manifest_hash, save_time, pdf_dir
- **Error handling**: Graceful fallback khi cache corrupted hoáº·c /dev/shm/ full

---

## PhiÃªn báº£n 0.2 (23/10/2025)

### ğŸ”„ Refactoring (23/10/2025 - Update)

#### API Simplification - Remove max_sources
- **Removed unused parameter**: `max_sources` khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trong implementation
- **Filtering via source_hashes**: User Ä‘Ã£ tá»± control sá»‘ lÆ°á»£ng qua hash selection
- **Cleaner API**: Simplified NewRAGQuerySchema (2 params instead of 3)
- **Code cleanup**: Removed dead code tá»« types.ts, handler, tool definition

#### New Tool: listNewRAGSources
- **MCP discovery tool**: List all hundreds of books vá»›i filename + hash qua MCP
- **Replace Bash workflow**: KhÃ´ng cáº§n run bash script trá»±c tiáº¿p
- **Consistent UX**: Follow pattern cá»§a listRAGCollections
- **30s timeout**: Fast listing vá»›i error handling

#### Workflow Enhancement
- **MANDATORY step**: Call listNewRAGSources() FIRST before queryNewRAG
- **Updated documentation**: Clear 3-step workflow trong tool description
- **Better discoverability**: User discover PDFs qua MCP tool, khÃ´ng qua docs
- **Example-driven**: Workflow example ngay trong tool description

### ğŸš€ TÃ­nh nÄƒng má»›i

#### NewRAG MCP Tool - Cross-Project Knowledge Search
- **MCP server integration**: ThÃªm `queryNewRAG` tool vÃ o DKM Knowledge Base MCP
- **Multi-query support**: 1-3 parallel queries vá»›i source filtering
- **Hash-based filtering**: Select specific books qua 32-char MD5 hash
- **Cross-project service**: Gá»i tá»« Báº¤T Ká»² project nÃ o khÃ´ng cáº§n CD
- **Discovery commands**: `--list-pdfs`, `--list-sources`, `--help` vá»›i absolute paths

#### Workflow UX Improvement
- **Absolute path workflow**: KhÃ´ng cáº§n CD sang mini-rag directory
- **From ANY project**: `~/Projects/mini-rag/multi-query/run-multiquery.sh --list-pdfs`
- **Simplified steps**: Tá»« 5 steps â†’ 4 steps (remove CD requirement)
- **Cross-project compatibility**: Perfect cho AI searching tá»« project khÃ¡c

### ğŸ”§ Cáº£i thiá»‡n ká»¹ thuáº­t

#### MCP Server Architecture
- **TypeScript handler**: `newrag-handler.ts` vá»›i execa subprocess
- **Config centralization**: `NEWRAG_CONFIG` trong `config.ts`
- **Auto working directory**: `cwd` tá»± Ä‘á»™ng set trong execa call
- **Timeout management**: 300s timeout cho large queries
- **Error handling**: Graceful timeout vÃ  exit code handling

#### Code Quality
- **Tool definition refactor**: Documentation pháº£n Ã¡nh Ä‘Ãºng cross-project usage
- **Consistent with implementation**: Workflow match vá»›i actual code behavior
- **User-centric design**: KhÃ´ng assume user Ä‘ang á»Ÿ project nÃ o

### ğŸ“š Documentation

#### MCP Tool Description
- **Discovery commands**: Clear instructions vá»›i absolute paths
- **Workflow guide**: Step-by-step tá»« listing PDFs Ä‘áº¿n query
- **Critical rules**: Max sources, hash format, performance warnings
- **Examples**: Practical query patterns vá»›i source filtering

#### Memory Records
- **Implementation record**: `2025-10-23-newrag-mcp-implementation.md`
- **WBS plan**: `2025-10-23-newrag-mcp-wbs-plan.md`
- **Workflow refactor**: `2025-10-23-queryNewRAG-workflow-refactor.md`

### ğŸ—ï¸ Files Added/Modified

```
ts-mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ newrag-handler.ts      # NEW: NewRAG MCP handler
â”‚   â”œâ”€â”€ config.ts              # MODIFIED: Add NEWRAG_CONFIG
â”‚   â”œâ”€â”€ index.ts               # MODIFIED: Add queryNewRAG route
â”‚   â”œâ”€â”€ tool-definitions.ts    # MODIFIED: Add queryNewRAG tool
â”‚   â””â”€â”€ types.ts               # MODIFIED: Add NewRAGQueryParams

.fong/.memory/short-term/
â”œâ”€â”€ 2025-10-23-newrag-mcp-implementation.md
â”œâ”€â”€ 2025-10-23-newrag-mcp-wbs-plan.md
â””â”€â”€ 2025-10-23-queryNewRAG-workflow-refactor.md
```

### ğŸ¯ Use Cases

#### AI Knowledge Search from Any Project
```bash
# Äang á»Ÿ /home/fong/Projects/laravel-app
# Search knowledge qua NewRAG MCP
/home/fong/Projects/mini-rag/multi-query/run-multiquery.sh --list-pdfs | jq ...
```

#### MCP Tool Integration
```typescript
// From ANY Claude Code session
mcp__dkm-knowledgebase__queryNewRAG({
  queries: ["SOLID principles", "clean code"],
  source_hashes: "838cc6ac8cb0d8ddb98fdb1ae0c8a443,41d80961ba66da6a1294aa9624cea15d",
  max_sources: 9
})
```

### ğŸ”¬ Technical Specifications

#### MCP Handler Details
```typescript
// Auto working directory setup
await execa(NEWRAG_CONFIG.runnerPath, args, {
  timeout: NEWRAG_CONFIG.timeout,
  cwd: NEWRAG_CONFIG.workDir,  // Auto CD
});
```

#### Performance
- **Timeout**: 300s (5 minutes) cho large queries
- **Max sources**: 9 books (cognitive load limit)
- **Max queries**: 3 parallel queries per request
- **Output**: Structured JSON vá»›i results vÃ  timing

### ğŸ› Bug Fixes

#### Documentation UX Issues
- **Fixed**: Workflow yÃªu cáº§u CD sang mini-rag directory
- **Root cause**: Documentation copy tá»« local development docs
- **Solution**: Refactor sang absolute path workflow
- **Impact**: Users cÃ³ thá»ƒ query tá»« ANY project

### ğŸ‰ Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c

âœ… **Cross-project service**: MCP tool hoáº¡t Ä‘á»™ng tá»« báº¥t ká»³ project nÃ o
âœ… **UX improvement**: KhÃ´ng cáº§n CD, dÃ¹ng absolute paths
âœ… **Consistent design**: Documentation match implementation
âœ… **Memory alignment**: Full documentation trong .memory/
âœ… **Git workflow**: Clean feature branch â†’ main merge

### ğŸ”„ Migration Guide

#### Tá»« old workflow:
```bash
cd /home/fong/Projects/mini-rag/multi-query
./run-multiquery.sh --list-pdfs
```

#### Sang new workflow:
```bash
# Tá»« Báº¤T Ká»² Ä‘Ã¢u
/home/fong/Projects/mini-rag/multi-query/run-multiquery.sh --list-pdfs
```

---

**Commits**:
- 43da860: refactor(mcp): Remove max_sources param and add listNewRAGSources tool
- c802c8c: feat(mcp): Add NewRAG multi-query tool to MCP server
- 7827fee: refactor: Update queryNewRAG workflow to use absolute paths

---

## PhiÃªn báº£n 0.1 (11/09/2025)

### ğŸš€ TÃ­nh nÄƒng má»›i

#### Pure Retrieval System  
- **Loáº¡i bá» hoÃ n toÃ n OpenAI/LLM generation**: Chuyá»ƒn tá»« RAG sang pure retrieval system
- **AI-to-AI pipeline integration**: Tá»‘i Æ°u cho viá»‡c feed context vÃ o AI systems khÃ¡c
- **Structured output format**: `[document.pdf] content...` vá»›i separator `---`
- **Source attribution**: Má»—i chunk Ä‘á»u cÃ³ tÃªn file nguá»“n Ä‘á»ƒ truy váº¿t

#### Smart Caching System
- **Manifest-based tracking**: Sá»­ dá»¥ng MD5 hash Ä‘á»ƒ detect thay Ä‘á»•i PDF files
- **Intelligent rebuild**: Chá»‰ rebuild khi files thá»±c sá»± thay Ä‘á»•i
- **Performance boost**: Tá»« 45s rebuild â†’ 0.17s cache load (265x faster)
- **Folder structure**: Vector store trong `.mini_rag_index/`, manifest.json á»Ÿ root level

#### Results Management
- **Automated saving**: Má»—i query tá»± Ä‘á»™ng save vÃ o `/results/` folder
- **Timestamped files**: Format `{timestamp}-{uuid}.md` 
- **Structured markdown**: Bao gá»“m query, PDF directory, context chunks, metadata
- **Source tracking**: Ghi rÃµ file nguá»“n vÃ  ná»™i dung cho tá»«ng chunk

#### Example Structure Reorganization
- **code-examples/**: Chá»©a demo scripts vÃ  AI integration examples
- **pdf-documents/**: Chá»©a sample PDFs vá»›i manifest tracking
- **Automation script**: `run.sh` vá»›i absolute paths, tá»± Ä‘á»™ng activate venv

### ğŸ”§ Cáº£i thiá»‡n ká»¹ thuáº­t

#### Configuration Updates
- **Pure HuggingFace**: Loáº¡i bá» táº¥t cáº£ OpenAI dependencies  
- **Fallback embeddings**: DummyHashEmbeddings khi khÃ´ng cÃ³ sentence-transformers
- **Environment variables**: Simplified config chá»‰ vá»›i HF embeddings
- **Error handling**: Graceful fallback cho offline operation

#### Performance Optimizations  
- **Lazy loading**: PDF loading/splitting chá»‰ khi cáº§n rebuild vector store
- **Cached retrieval**: Skip hoÃ n toÃ n PDF processing khi cÃ³ cache
- **Memory efficiency**: Optimized document loading vÃ  chunking
- **Fast startup**: 0.17s vs 45s cho subsequent runs

#### Code Quality
- **Modular architecture**: TÃ¡ch biá»‡t concerns theo pipeline pattern
- **Type hints**: Full type annotations vá»›i `from __future__ import annotations`
- **Error handling**: Comprehensive exception handling vÃ  logging
- **Rich console**: Beautiful console output vá»›i progress indicators

### ğŸ“š Documentation

#### AI-Focused README
- **AI-to-AI integration patterns**: Shell, Python, API service examples
- **Query strategies**: Natural language, keyword/phrase, structured queries
- **Pipeline integration**: Comprehensive examples cho downstream AI systems
- **Performance metrics**: Detailed caching vÃ  retrieval benchmarks

#### Vietnamese Documentation  
- **CHANGELOGS.md**: Chi tiáº¿t thay Ä‘á»•i phiÃªn báº£n báº±ng tiáº¿ng Viá»‡t
- **Code comments**: Vietnamese comments cho core functions
- **Error messages**: Vietnamese error output cho user experience

### ğŸ—ï¸ Cáº¥u trÃºc dá»± Ã¡n

```
mini-rag/
â”œâ”€â”€ src/minirag/           # Core modules
â”‚   â”œâ”€â”€ config.py         # Settings vá»›i HF embeddings only
â”‚   â”œâ”€â”€ embedder.py       # HF embeddings vá»›i fallback  
â”‚   â”œâ”€â”€ pipeline.py       # Pure retrieval pipeline
â”‚   â”œâ”€â”€ vectorstore.py    # FAISS vá»›i smart caching
â”‚   â”œâ”€â”€ loader.py         # PDF document loading
â”‚   â”œâ”€â”€ splitter.py       # Text chunking
â”‚   â””â”€â”€ utils.py          # Timing vÃ  utilities
â”œâ”€â”€ example/
â”‚   â”œâ”€â”€ code-examples/    # Demo scripts
â”‚   â””â”€â”€ pdf-documents/    # Sample PDFs vá»›i manifest  
â”œâ”€â”€ results/              # Auto-saved query results
â”œâ”€â”€ logs/                 # Application logs
â”œâ”€â”€ run.sh               # Automation script
â”œâ”€â”€ main-minirag.py      # Entry point
â””â”€â”€ requirements.txt     # Dependencies
```

### ğŸ¯ Use Cases

#### AI System Preprocessing
- Extract structured context tá»« PDF collections
- Feed vÃ o downstream AI models
- Document-based RAG system backends  
- Automated research analysis workflows

#### Query Examples
```bash
# Natural language (comprehensive context)
./run.sh "What research methodologies are discussed?" /path/to/pdfs

# Keywords (specific term extraction)  
./run.sh "machine learning algorithms neural networks" /path/to/pdfs

# Structured (systematic analysis)
./run.sh "List: 1) methodologies 2) datasets 3) metrics" /path/to/pdfs
```

### ğŸ”¬ Technical Specifications

#### Dependencies
- **LangChain**: Document processing vÃ  retrieval
- **FAISS**: Vector similarity search  
- **Rich**: Console UI vÃ  progress indicators
- **Optional**: sentence-transformers (fallback to DummyHashEmbeddings)

#### Performance
- **First run**: ~45s (build vector index cho 7 research papers)
- **Cached runs**: ~0.17s (265x faster)
- **Memory**: Efficient vá»›i streaming file hashing
- **Storage**: Smart caching vá»›i MD5 tracking

#### Environment Variables
```bash
export HF_EMBEDDINGS_MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2"
export CHUNK_SIZE=1200
export CHUNK_OVERLAP=150  
export TOP_K=4
```

### ğŸš§ Breaking Changes

#### Removed OpenAI Integration
- **KHÃ”NG cÃ²n**: `OPENAI_API_KEY`, `OPENAI_MODEL_NAME`
- **KHÃ”NG cÃ²n**: LLM generation trong pipeline
- **KHÃ”NG cÃ²n**: OpenAI embeddings option

#### API Changes
- `answer_question()` â†’ returns pure context (khÃ´ng pháº£i generated answer)
- `get_context()` â†’ new primary function cho retrieval
- `build_or_load_vectorstore()` â†’ khÃ´ng cáº§n docs parameter

### ğŸ‰ Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c

âœ… **Cache Performance**: 265x speedup (45s â†’ 0.17s)  
âœ… **Pure Retrieval**: 100% context extraction, 0% generation  
âœ… **AI Integration**: Complete examples cho 3 integration patterns  
âœ… **Documentation**: Comprehensive Vietnamese docs  
âœ… **Results Management**: Auto-save vá»›i structured markdown  
âœ… **Offline Capable**: Hoáº¡t Ä‘á»™ng 100% offline vá»›i fallback embeddings  

---

**LÆ°u Ã½**: ÄÃ¢y lÃ  phiÃªn báº£n Ä‘áº§u tiÃªn focus vÃ o pure retrieval cho AI-to-AI integration. KhÃ´ng cÃ²n support OpenAI LLM generation.